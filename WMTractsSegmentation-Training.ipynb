{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models, datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"WMTdata\"\n",
    "data = [im for im in Path(root, \"T1_tif\").glob(\"*.tif\")]; data.sort()\n",
    "annotations = [im for im in Path(root, \"AnnotationsTif\").glob(\"*.tif\")]; annotations.sort()\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data, annotations, test_size=0.20, random_state=1) #Train/Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracts(Dataset):\n",
    "    \"\"\" BrainPTM\n",
    "    \"\"\"\n",
    "    def __init__(self, datadir, maskdir, transform=None, target_transform=None):\n",
    "    \n",
    "        self.imgs = datadir\n",
    "        self.targets= maskdir  \n",
    "        assert len(self.imgs) == len(self.targets)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self,ind):\n",
    "        \n",
    "        image = Image.open(self.imgs[ind]).convert(\"RGB\")\n",
    "        target = Image.open(self.targets[ind])\n",
    "        #print(self.imgs[ind])\n",
    "        #print(self.targets[ind])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return image, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.confusion_matrix = np.zeros((self.num_class,)*2)\n",
    "\n",
    "    def Pixel_Accuracy(self):\n",
    "        Acc = np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
    "        return Acc\n",
    "\n",
    "    def Pixel_Accuracy_Class(self):\n",
    "        Acc = np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
    "        Acc = np.nanmean(Acc)\n",
    "        return Acc\n",
    "\n",
    "    def Mean_Intersection_over_Union(self):\n",
    "        MIoU = np.diag(self.confusion_matrix) / (\n",
    "                    np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n",
    "                    np.diag(self.confusion_matrix))\n",
    "        MIoU = np.nanmean(MIoU)\n",
    "        return MIoU\n",
    "\n",
    "    def Frequency_Weighted_Intersection_over_Union(self):\n",
    "        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n",
    "        iu = np.diag(self.confusion_matrix) / (\n",
    "                    np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n",
    "                    np.diag(self.confusion_matrix))\n",
    "\n",
    "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "        return FWIoU\n",
    "\n",
    "    def _generate_matrix(self, gt_image, pre_image):\n",
    "        mask = (gt_image >= 0) & (gt_image < self.num_class)\n",
    "        label = self.num_class * gt_image[mask].astype('int') + pre_image[mask]\n",
    "        count = np.bincount(label, minlength=self.num_class**2)\n",
    "        confusion_matrix = count.reshape(self.num_class, self.num_class)\n",
    "        return confusion_matrix\n",
    "\n",
    "    def add_batch(self, gt_image, pre_image):\n",
    "        assert gt_image.shape == pre_image.shape\n",
    "        self.confusion_matrix += self._generate_matrix(gt_image, pre_image)\n",
    "\n",
    "    def reset(self):\n",
    "        self.confusion_matrix = np.zeros((self.num_class,) * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader= torch.utils.data.DataLoader(Tracts(\n",
    "    Xtrain, ytrain,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform= transforms.ToTensor()\n",
    "    ), batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader= torch.utils.data.DataLoader(Tracts(\n",
    "    Xtest, ytest,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform= transforms.ToTensor()\n",
    "    ), batch_size=64, shuffle=True)\n",
    "\n",
    "model = models.segmentation.deeplabv3_resnet50(pretrained=False, num_classes=2)\n",
    "\n",
    "cp_model = copy.deepcopy(model)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.000001, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "metrics = Evaluator(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        #if args.cuda:\n",
    "        #data, target = data.cuda(), target.cuda() * 255.\n",
    "        data, target = data.cuda(), target.cuda() \n",
    "        \n",
    "        data, target = Variable(data), Variable(target).long().squeeze_(1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output['out'], target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    metrics.reset()\n",
    "    test_loss = 0.\n",
    "    for data, target in test_loader:\n",
    "        #if args.cuda:\n",
    "        data, target = data.cuda(), target.cuda() #* 255.\n",
    "        data, target = Variable(data), Variable(target).long().squeeze_(1)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        test_loss += criterion(output['out'], target).item()\n",
    "        pred = output['out'].cpu()\n",
    "        pred = F.softmax(pred, dim=1).numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        #if demo:\n",
    "        #    out = pred[0,:,:]\n",
    "        #    label = target[0,:,:]\n",
    "        metrics.add_batch(target, pred)\n",
    "\n",
    "    Acc = metrics.Pixel_Accuracy()\n",
    "    Acc_class = metrics.Pixel_Accuracy_Class()\n",
    "    mIoU = metrics.Mean_Intersection_over_Union()\n",
    "    FWIoU = metrics.Frequency_Weighted_Intersection_over_Union()\n",
    "\n",
    "    print('Validation:')\n",
    "    print('[Epoch: %d, numImages: %5d]' % (epoch, len(test_loader.dataset)))\n",
    "    print(\"Acc:{}, Acc_class:{}, mIoU:{}, fwIoU: {}\".format(\n",
    "        Acc, Acc_class, mIoU, FWIoU))\n",
    "    print('Loss: %.3f' % test_loss)\n",
    "    return test_loss\n",
    "  \n",
    "    \n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed\n",
    "       by 10 at every specified step\n",
    "       Adapted from PyTorch Imagenet example:\n",
    "       https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = 0.01 * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3696 (0%)]\tLoss: 0.833463\n",
      "Train Epoch: 1 [400/3696 (11%)]\tLoss: 0.819305\n",
      "Train Epoch: 1 [800/3696 (22%)]\tLoss: 0.814612\n",
      "Train Epoch: 1 [1200/3696 (32%)]\tLoss: 0.810900\n",
      "Train Epoch: 1 [1600/3696 (43%)]\tLoss: 0.810786\n",
      "Train Epoch: 1 [2000/3696 (54%)]\tLoss: 0.801140\n",
      "Train Epoch: 1 [2400/3696 (65%)]\tLoss: 0.795103\n",
      "Train Epoch: 1 [2800/3696 (76%)]\tLoss: 0.788579\n",
      "Train Epoch: 1 [3200/3696 (87%)]\tLoss: 0.784700\n",
      "Train Epoch: 1 [3600/3696 (97%)]\tLoss: 0.779843\n",
      "Validation:\n",
      "[Epoch: 1, numImages:   924]\n",
      "Acc:0.40246112304217774, Acc_class:0.5186364549625793, mIoU:0.2029616888008571, fwIoU: 0.3984926365601004\n",
      "Loss: 172.084\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 281.72s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 2 [0/3696 (0%)]\tLoss: 0.784056\n",
      "Train Epoch: 2 [400/3696 (11%)]\tLoss: 0.776606\n",
      "Train Epoch: 2 [800/3696 (22%)]\tLoss: 0.771392\n",
      "Train Epoch: 2 [1200/3696 (32%)]\tLoss: 0.769298\n",
      "Train Epoch: 2 [1600/3696 (43%)]\tLoss: 0.762388\n",
      "Train Epoch: 2 [2000/3696 (54%)]\tLoss: 0.757416\n",
      "Train Epoch: 2 [2400/3696 (65%)]\tLoss: 0.751560\n",
      "Train Epoch: 2 [2800/3696 (76%)]\tLoss: 0.754271\n",
      "Train Epoch: 2 [3200/3696 (87%)]\tLoss: 0.744788\n",
      "Train Epoch: 2 [3600/3696 (97%)]\tLoss: 0.744946\n",
      "Validation:\n",
      "[Epoch: 2, numImages:   924]\n",
      "Acc:0.49764502352392975, Acc_class:0.5092930567415206, mIoU:0.2507886808985037, fwIoU: 0.49379356961483695\n",
      "Loss: 164.443\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 287.93s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 3 [0/3696 (0%)]\tLoss: 0.737391\n",
      "Train Epoch: 3 [400/3696 (11%)]\tLoss: 0.734170\n",
      "Train Epoch: 3 [800/3696 (22%)]\tLoss: 0.736961\n",
      "Train Epoch: 3 [1200/3696 (32%)]\tLoss: 0.727705\n",
      "Train Epoch: 3 [1600/3696 (43%)]\tLoss: 0.723552\n",
      "Train Epoch: 3 [2000/3696 (54%)]\tLoss: 0.722768\n",
      "Train Epoch: 3 [2400/3696 (65%)]\tLoss: 0.716272\n",
      "Train Epoch: 3 [2800/3696 (76%)]\tLoss: 0.709448\n",
      "Train Epoch: 3 [3200/3696 (87%)]\tLoss: 0.706378\n",
      "Train Epoch: 3 [3600/3696 (97%)]\tLoss: 0.698811\n",
      "Validation:\n",
      "[Epoch: 3, numImages:   924]\n",
      "Acc:0.5916618871941137, Acc_class:0.496140453621157, mIoU:0.2979018453659224, fwIoU: 0.5878314866021523\n",
      "Loss: 156.855\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 281.85s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 4 [0/3696 (0%)]\tLoss: 0.703311\n",
      "Train Epoch: 4 [400/3696 (11%)]\tLoss: 0.697758\n",
      "Train Epoch: 4 [800/3696 (22%)]\tLoss: 0.690695\n",
      "Train Epoch: 4 [1200/3696 (32%)]\tLoss: 0.688045\n",
      "Train Epoch: 4 [1600/3696 (43%)]\tLoss: 0.690764\n",
      "Train Epoch: 4 [2000/3696 (54%)]\tLoss: 0.680611\n",
      "Train Epoch: 4 [2400/3696 (65%)]\tLoss: 0.675151\n",
      "Train Epoch: 4 [2800/3696 (76%)]\tLoss: 0.671655\n",
      "Train Epoch: 4 [3200/3696 (87%)]\tLoss: 0.669420\n",
      "Train Epoch: 4 [3600/3696 (97%)]\tLoss: 0.668870\n",
      "Validation:\n",
      "[Epoch: 4, numImages:   924]\n",
      "Acc:0.6610561295619889, Acc_class:0.5178508153276863, mIoU:0.3330022475808307, fwIoU: 0.6570612975730766\n",
      "Loss: 151.085\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 288.09s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 5 [0/3696 (0%)]\tLoss: 0.662492\n",
      "Train Epoch: 5 [400/3696 (11%)]\tLoss: 0.666523\n",
      "Train Epoch: 5 [800/3696 (22%)]\tLoss: 0.661610\n",
      "Train Epoch: 5 [1200/3696 (32%)]\tLoss: 0.652038\n",
      "Train Epoch: 5 [1600/3696 (43%)]\tLoss: 0.653043\n",
      "Train Epoch: 5 [2000/3696 (54%)]\tLoss: 0.645858\n",
      "Train Epoch: 5 [2400/3696 (65%)]\tLoss: 0.643618\n",
      "Train Epoch: 5 [2800/3696 (76%)]\tLoss: 0.645698\n",
      "Train Epoch: 5 [3200/3696 (87%)]\tLoss: 0.637755\n",
      "Train Epoch: 5 [3600/3696 (97%)]\tLoss: 0.630503\n",
      "Validation:\n",
      "[Epoch: 5, numImages:   924]\n",
      "Acc:0.7103522201178452, Acc_class:0.5292890516595432, mIoU:0.35795682025446224, fwIoU: 0.7062412236563365\n",
      "Loss: 146.698\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 281.79s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 6 [0/3696 (0%)]\tLoss: 0.633105\n",
      "Train Epoch: 6 [400/3696 (11%)]\tLoss: 0.629203\n",
      "Train Epoch: 6 [800/3696 (22%)]\tLoss: 0.632086\n",
      "Train Epoch: 6 [1200/3696 (32%)]\tLoss: 0.627274\n",
      "Train Epoch: 6 [1600/3696 (43%)]\tLoss: 0.619536\n",
      "Train Epoch: 6 [2000/3696 (54%)]\tLoss: 0.615399\n",
      "Train Epoch: 6 [2400/3696 (65%)]\tLoss: 0.611245\n",
      "Train Epoch: 6 [2800/3696 (76%)]\tLoss: 0.606854\n",
      "Train Epoch: 6 [3200/3696 (87%)]\tLoss: 0.603471\n",
      "Train Epoch: 6 [3600/3696 (97%)]\tLoss: 0.603288\n",
      "Validation:\n",
      "[Epoch: 6, numImages:   924]\n",
      "Acc:0.7695813346448112, Acc_class:0.5279145341748054, mIoU:0.38775095148953675, fwIoU: 0.7653466112641507\n",
      "Loss: 142.318\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 287.84s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 7 [0/3696 (0%)]\tLoss: 0.601517\n",
      "Train Epoch: 7 [400/3696 (11%)]\tLoss: 0.596420\n",
      "Train Epoch: 7 [800/3696 (22%)]\tLoss: 0.597394\n",
      "Train Epoch: 7 [1200/3696 (32%)]\tLoss: 0.591880\n",
      "Train Epoch: 7 [1600/3696 (43%)]\tLoss: 0.593643\n",
      "Train Epoch: 7 [2000/3696 (54%)]\tLoss: 0.587235\n",
      "Train Epoch: 7 [2400/3696 (65%)]\tLoss: 0.585063\n",
      "Train Epoch: 7 [2800/3696 (76%)]\tLoss: 0.581163\n",
      "Train Epoch: 7 [3200/3696 (87%)]\tLoss: 0.577698\n",
      "Train Epoch: 7 [3600/3696 (97%)]\tLoss: 0.571399\n",
      "Validation:\n",
      "[Epoch: 7, numImages:   924]\n",
      "Acc:0.8212928790321369, Acc_class:0.5247103893078375, mIoU:0.4137416698283363, fwIoU: 0.8169227532613618\n",
      "Loss: 137.207\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 281.77s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 8 [0/3696 (0%)]\tLoss: 0.574233\n",
      "Train Epoch: 8 [400/3696 (11%)]\tLoss: 0.569736\n",
      "Train Epoch: 8 [800/3696 (22%)]\tLoss: 0.566612\n",
      "Train Epoch: 8 [1200/3696 (32%)]\tLoss: 0.562532\n",
      "Train Epoch: 8 [1600/3696 (43%)]\tLoss: 0.559107\n",
      "Train Epoch: 8 [2000/3696 (54%)]\tLoss: 0.560381\n",
      "Train Epoch: 8 [2400/3696 (65%)]\tLoss: 0.554910\n",
      "Train Epoch: 8 [2800/3696 (76%)]\tLoss: 0.549095\n",
      "Train Epoch: 8 [3200/3696 (87%)]\tLoss: 0.552509\n",
      "Train Epoch: 8 [3600/3696 (97%)]\tLoss: 0.547391\n",
      "Validation:\n",
      "[Epoch: 8, numImages:   924]\n",
      "Acc:0.8757971267736893, Acc_class:0.5129160074866365, mIoU:0.4408442613982959, fwIoU: 0.871258602551509\n",
      "Loss: 130.976\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 287.89s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 9 [0/3696 (0%)]\tLoss: 0.544554\n",
      "Train Epoch: 9 [400/3696 (11%)]\tLoss: 0.540252\n",
      "Train Epoch: 9 [800/3696 (22%)]\tLoss: 0.544084\n",
      "Train Epoch: 9 [1200/3696 (32%)]\tLoss: 0.539340\n",
      "Train Epoch: 9 [1600/3696 (43%)]\tLoss: 0.536757\n",
      "Train Epoch: 9 [2000/3696 (54%)]\tLoss: 0.531768\n",
      "Train Epoch: 9 [2400/3696 (65%)]\tLoss: 0.527171\n",
      "Train Epoch: 9 [2800/3696 (76%)]\tLoss: 0.525365\n",
      "Train Epoch: 9 [3200/3696 (87%)]\tLoss: 0.524538\n",
      "Train Epoch: 9 [3600/3696 (97%)]\tLoss: 0.519961\n",
      "Validation:\n",
      "[Epoch: 9, numImages:   924]\n",
      "Acc:0.9146525358683562, Acc_class:0.5149073019268708, mIoU:0.46060499475518357, fwIoU: 0.9099628272127079\n",
      "Loss: 124.953\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 281.72s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 10 [0/3696 (0%)]\tLoss: 0.520537\n",
      "Train Epoch: 10 [400/3696 (11%)]\tLoss: 0.516301\n",
      "Train Epoch: 10 [800/3696 (22%)]\tLoss: 0.516860\n",
      "Train Epoch: 10 [1200/3696 (32%)]\tLoss: 0.512466\n",
      "Train Epoch: 10 [1600/3696 (43%)]\tLoss: 0.508844\n",
      "Train Epoch: 10 [2000/3696 (54%)]\tLoss: 0.509508\n",
      "Train Epoch: 10 [2400/3696 (65%)]\tLoss: 0.513098\n",
      "Train Epoch: 10 [2800/3696 (76%)]\tLoss: 0.503446\n",
      "Train Epoch: 10 [3200/3696 (87%)]\tLoss: 0.498390\n",
      "Train Epoch: 10 [3600/3696 (97%)]\tLoss: 0.495010\n",
      "Validation:\n",
      "[Epoch: 10, numImages:   924]\n",
      "Acc:0.9401557192084535, Acc_class:0.510713869917812, mIoU:0.4733261451403745, fwIoU: 0.9353600376117867\n",
      "Loss: 120.471\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 287.78s \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/3696 (0%)]\tLoss: 0.496714\n",
      "Train Epoch: 11 [400/3696 (11%)]\tLoss: 0.492307\n",
      "Train Epoch: 11 [800/3696 (22%)]\tLoss: 0.493428\n",
      "Train Epoch: 11 [1200/3696 (32%)]\tLoss: 0.492398\n",
      "Train Epoch: 11 [1600/3696 (43%)]\tLoss: 0.488550\n",
      "Train Epoch: 11 [2000/3696 (54%)]\tLoss: 0.482935\n",
      "Train Epoch: 11 [2400/3696 (65%)]\tLoss: 0.485030\n",
      "Train Epoch: 11 [2800/3696 (76%)]\tLoss: 0.484696\n",
      "Train Epoch: 11 [3200/3696 (87%)]\tLoss: 0.479723\n",
      "Train Epoch: 11 [3600/3696 (97%)]\tLoss: 0.483982\n",
      "Validation:\n",
      "[Epoch: 11, numImages:   924]\n",
      "Acc:0.9387317417102573, Acc_class:0.5148779677890862, mIoU:0.47294073994427294, fwIoU: 0.9339430803609311\n",
      "Loss: 120.514\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 281.67s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 12 [0/3696 (0%)]\tLoss: 0.476261\n",
      "Train Epoch: 12 [400/3696 (11%)]\tLoss: 0.469355\n",
      "Train Epoch: 12 [800/3696 (22%)]\tLoss: 0.452383\n",
      "Train Epoch: 12 [1200/3696 (32%)]\tLoss: 0.443622\n",
      "Train Epoch: 12 [1600/3696 (43%)]\tLoss: 0.434808\n",
      "Train Epoch: 12 [2000/3696 (54%)]\tLoss: 0.431851\n",
      "Train Epoch: 12 [2400/3696 (65%)]\tLoss: 0.419136\n",
      "Train Epoch: 12 [2800/3696 (76%)]\tLoss: 0.405507\n",
      "Train Epoch: 12 [3200/3696 (87%)]\tLoss: 0.400726\n",
      "Train Epoch: 12 [3600/3696 (97%)]\tLoss: 0.389495\n",
      "Validation:\n",
      "[Epoch: 12, numImages:   924]\n",
      "Acc:0.9843280272967773, Acc_class:0.505103524246008, mIoU:0.495553144525566, fwIoU: 0.9793296114344108\n",
      "Loss: 103.727\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 287.91s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 13 [0/3696 (0%)]\tLoss: 0.399210\n",
      "Train Epoch: 13 [400/3696 (11%)]\tLoss: 0.386342\n",
      "Train Epoch: 13 [800/3696 (22%)]\tLoss: 0.372108\n",
      "Train Epoch: 13 [1200/3696 (32%)]\tLoss: 0.378964\n",
      "Train Epoch: 13 [1600/3696 (43%)]\tLoss: 0.357269\n",
      "Train Epoch: 13 [2000/3696 (54%)]\tLoss: 0.358746\n",
      "Train Epoch: 13 [2400/3696 (65%)]\tLoss: 0.349953\n",
      "Train Epoch: 13 [2800/3696 (76%)]\tLoss: 0.356364\n",
      "Train Epoch: 13 [3200/3696 (87%)]\tLoss: 0.341465\n",
      "Train Epoch: 13 [3600/3696 (97%)]\tLoss: 0.327430\n",
      "Validation:\n",
      "[Epoch: 13, numImages:   924]\n",
      "Acc:0.9930624840292809, Acc_class:0.5014536111272109, mIoU:0.49828119333315113, fwIoU: 0.9880041568359325\n",
      "Loss: 90.956\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 281.64s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 14 [0/3696 (0%)]\tLoss: 0.332426\n",
      "Train Epoch: 14 [400/3696 (11%)]\tLoss: 0.326710\n",
      "Train Epoch: 14 [800/3696 (22%)]\tLoss: 0.319201\n",
      "Train Epoch: 14 [1200/3696 (32%)]\tLoss: 0.313525\n",
      "Train Epoch: 14 [1600/3696 (43%)]\tLoss: 0.307521\n",
      "Train Epoch: 14 [2000/3696 (54%)]\tLoss: 0.306882\n",
      "Train Epoch: 14 [2400/3696 (65%)]\tLoss: 0.296206\n",
      "Train Epoch: 14 [2800/3696 (76%)]\tLoss: 0.286957\n",
      "Train Epoch: 14 [3200/3696 (87%)]\tLoss: 0.289504\n",
      "Train Epoch: 14 [3600/3696 (97%)]\tLoss: 0.300579\n",
      "Validation:\n",
      "[Epoch: 14, numImages:   924]\n",
      "Acc:0.9945081276868386, Acc_class:0.5000259736577288, mIoU:0.49745711208179805, fwIoU: 0.989426752241235\n",
      "Loss: 83.485\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 287.87s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 15 [0/3696 (0%)]\tLoss: 0.285775\n",
      "Train Epoch: 15 [400/3696 (11%)]\tLoss: 0.272908\n",
      "Train Epoch: 15 [800/3696 (22%)]\tLoss: 0.276701\n",
      "Train Epoch: 15 [1200/3696 (32%)]\tLoss: 0.272844\n",
      "Train Epoch: 15 [1600/3696 (43%)]\tLoss: 0.266956\n",
      "Train Epoch: 15 [2000/3696 (54%)]\tLoss: 0.272800\n",
      "Train Epoch: 15 [2400/3696 (65%)]\tLoss: 0.255633\n",
      "Train Epoch: 15 [2800/3696 (76%)]\tLoss: 0.255424\n",
      "Train Epoch: 15 [3200/3696 (87%)]\tLoss: 0.245555\n",
      "Train Epoch: 15 [3600/3696 (97%)]\tLoss: 0.243789\n",
      "Validation:\n",
      "[Epoch: 15, numImages:   924]\n",
      "Acc:0.9947839748865139, Acc_class:0.499953188369118, mIoU:0.4973976156389928, fwIoU: 0.9896991830406883\n",
      "Loss: 73.930\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 281.74s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 16 [0/3696 (0%)]\tLoss: 0.241159\n",
      "Train Epoch: 16 [400/3696 (11%)]\tLoss: 0.262383\n",
      "Train Epoch: 16 [800/3696 (22%)]\tLoss: 0.241449\n",
      "Train Epoch: 16 [1200/3696 (32%)]\tLoss: 0.238853\n",
      "Train Epoch: 16 [1600/3696 (43%)]\tLoss: 0.231009\n",
      "Train Epoch: 16 [2000/3696 (54%)]\tLoss: 0.224889\n",
      "Train Epoch: 16 [2400/3696 (65%)]\tLoss: 0.223987\n",
      "Train Epoch: 16 [2800/3696 (76%)]\tLoss: 0.223066\n",
      "Train Epoch: 16 [3200/3696 (87%)]\tLoss: 0.220763\n",
      "Train Epoch: 16 [3600/3696 (97%)]\tLoss: 0.231010\n",
      "Validation:\n",
      "[Epoch: 16, numImages:   924]\n",
      "Acc:0.9948554321112915, Acc_class:0.4999891005469936, mIoU:0.4974334224294523, fwIoU: 0.989770275814455\n",
      "Loss: 70.790\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 287.88s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 17 [0/3696 (0%)]\tLoss: 0.219668\n",
      "Train Epoch: 17 [400/3696 (11%)]\tLoss: 0.220825\n",
      "Train Epoch: 17 [800/3696 (22%)]\tLoss: 0.232613\n",
      "Train Epoch: 17 [1200/3696 (32%)]\tLoss: 0.210505\n",
      "Train Epoch: 17 [1600/3696 (43%)]\tLoss: 0.200910\n",
      "Train Epoch: 17 [2000/3696 (54%)]\tLoss: 0.212349\n",
      "Train Epoch: 17 [2400/3696 (65%)]\tLoss: 0.209624\n",
      "Train Epoch: 17 [2800/3696 (76%)]\tLoss: 0.209362\n",
      "Train Epoch: 17 [3200/3696 (87%)]\tLoss: 0.218765\n",
      "Train Epoch: 17 [3600/3696 (97%)]\tLoss: 0.214623\n",
      "Validation:\n",
      "[Epoch: 17, numImages:   924]\n",
      "Acc:0.9948832047220719, Acc_class:0.4999973442103461, mIoU:0.49744160236103596, fwIoU: 0.9897978484278307\n",
      "Loss: 63.463\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 281.80s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 18 [0/3696 (0%)]\tLoss: 0.192663\n",
      "Train Epoch: 18 [400/3696 (11%)]\tLoss: 0.191048\n",
      "Train Epoch: 18 [800/3696 (22%)]\tLoss: 0.185945\n",
      "Train Epoch: 18 [1200/3696 (32%)]\tLoss: 0.187474\n",
      "Train Epoch: 18 [1600/3696 (43%)]\tLoss: 0.195462\n",
      "Train Epoch: 18 [2000/3696 (54%)]\tLoss: 0.188866\n",
      "Train Epoch: 18 [2400/3696 (65%)]\tLoss: 0.177458\n",
      "Train Epoch: 18 [2800/3696 (76%)]\tLoss: 0.191449\n",
      "Train Epoch: 18 [3200/3696 (87%)]\tLoss: 0.195118\n",
      "Train Epoch: 18 [3600/3696 (97%)]\tLoss: 0.172383\n",
      "Validation:\n",
      "[Epoch: 18, numImages:   924]\n",
      "Acc:0.9948874322653619, Acc_class:0.4999994688420692, mIoU:0.49744371613268096, fwIoU: 0.9898020543619873\n",
      "Loss: 62.386\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 287.86s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 19 [0/3696 (0%)]\tLoss: 0.184299\n",
      "Train Epoch: 19 [400/3696 (11%)]\tLoss: 0.169206\n",
      "Train Epoch: 19 [800/3696 (22%)]\tLoss: 0.187788\n",
      "Train Epoch: 19 [1200/3696 (32%)]\tLoss: 0.166562\n",
      "Train Epoch: 19 [1600/3696 (43%)]\tLoss: 0.175650\n",
      "Train Epoch: 19 [2000/3696 (54%)]\tLoss: 0.161860\n",
      "Train Epoch: 19 [2400/3696 (65%)]\tLoss: 0.167196\n",
      "Train Epoch: 19 [2800/3696 (76%)]\tLoss: 0.171803\n",
      "Train Epoch: 19 [3200/3696 (87%)]\tLoss: 0.184988\n",
      "Train Epoch: 19 [3600/3696 (97%)]\tLoss: 0.155746\n",
      "Validation:\n",
      "[Epoch: 19, numImages:   924]\n",
      "Acc:0.9948883130035474, Acc_class:0.4999999114736782, mIoU:0.4974441565017737, fwIoU: 0.98980293059827\n",
      "Loss: 56.410\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 281.84s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 20 [0/3696 (0%)]\tLoss: 0.174071\n",
      "Train Epoch: 20 [400/3696 (11%)]\tLoss: 0.175088\n",
      "Train Epoch: 20 [800/3696 (22%)]\tLoss: 0.155746\n",
      "Train Epoch: 20 [1200/3696 (32%)]\tLoss: 0.153533\n",
      "Train Epoch: 20 [1600/3696 (43%)]\tLoss: 0.159636\n",
      "Train Epoch: 20 [2000/3696 (54%)]\tLoss: 0.162525\n",
      "Train Epoch: 20 [2400/3696 (65%)]\tLoss: 0.157341\n",
      "Train Epoch: 20 [2800/3696 (76%)]\tLoss: 0.158979\n",
      "Train Epoch: 20 [3200/3696 (87%)]\tLoss: 0.146572\n",
      "Train Epoch: 20 [3600/3696 (97%)]\tLoss: 0.143889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "[Epoch: 20, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 52.938\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 288.19s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 21 [0/3696 (0%)]\tLoss: 0.155528\n",
      "Train Epoch: 21 [400/3696 (11%)]\tLoss: 0.142538\n",
      "Train Epoch: 21 [800/3696 (22%)]\tLoss: 0.149166\n",
      "Train Epoch: 21 [1200/3696 (32%)]\tLoss: 0.140016\n",
      "Train Epoch: 21 [1600/3696 (43%)]\tLoss: 0.157674\n",
      "Train Epoch: 21 [2000/3696 (54%)]\tLoss: 0.138114\n",
      "Train Epoch: 21 [2400/3696 (65%)]\tLoss: 0.138496\n",
      "Train Epoch: 21 [2800/3696 (76%)]\tLoss: 0.136193\n",
      "Train Epoch: 21 [3200/3696 (87%)]\tLoss: 0.132024\n",
      "Train Epoch: 21 [3600/3696 (97%)]\tLoss: 0.146318\n",
      "Validation:\n",
      "[Epoch: 21, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 51.032\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 281.74s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 22 [0/3696 (0%)]\tLoss: 0.144628\n",
      "Train Epoch: 22 [400/3696 (11%)]\tLoss: 0.145603\n",
      "Train Epoch: 22 [800/3696 (22%)]\tLoss: 0.139640\n",
      "Train Epoch: 22 [1200/3696 (32%)]\tLoss: 0.137819\n",
      "Train Epoch: 22 [1600/3696 (43%)]\tLoss: 0.141196\n",
      "Train Epoch: 22 [2000/3696 (54%)]\tLoss: 0.138666\n",
      "Train Epoch: 22 [2400/3696 (65%)]\tLoss: 0.126732\n",
      "Train Epoch: 22 [2800/3696 (76%)]\tLoss: 0.131322\n",
      "Train Epoch: 22 [3200/3696 (87%)]\tLoss: 0.122062\n",
      "Train Epoch: 22 [3600/3696 (97%)]\tLoss: 0.123979\n",
      "Validation:\n",
      "[Epoch: 22, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 49.146\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 287.86s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 23 [0/3696 (0%)]\tLoss: 0.139863\n",
      "Train Epoch: 23 [400/3696 (11%)]\tLoss: 0.119795\n",
      "Train Epoch: 23 [800/3696 (22%)]\tLoss: 0.123201\n",
      "Train Epoch: 23 [1200/3696 (32%)]\tLoss: 0.138812\n",
      "Train Epoch: 23 [1600/3696 (43%)]\tLoss: 0.131251\n",
      "Train Epoch: 23 [2000/3696 (54%)]\tLoss: 0.142931\n",
      "Train Epoch: 23 [2400/3696 (65%)]\tLoss: 0.168064\n",
      "Train Epoch: 23 [2800/3696 (76%)]\tLoss: 0.133714\n",
      "Train Epoch: 23 [3200/3696 (87%)]\tLoss: 0.116375\n",
      "Train Epoch: 23 [3600/3696 (97%)]\tLoss: 0.113974\n",
      "Validation:\n",
      "[Epoch: 23, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 46.878\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 281.82s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 24 [0/3696 (0%)]\tLoss: 0.116007\n",
      "Train Epoch: 24 [400/3696 (11%)]\tLoss: 0.119909\n",
      "Train Epoch: 24 [800/3696 (22%)]\tLoss: 0.146108\n",
      "Train Epoch: 24 [1200/3696 (32%)]\tLoss: 0.134187\n",
      "Train Epoch: 24 [1600/3696 (43%)]\tLoss: 0.110538\n",
      "Train Epoch: 24 [2000/3696 (54%)]\tLoss: 0.113760\n",
      "Train Epoch: 24 [2400/3696 (65%)]\tLoss: 0.120796\n",
      "Train Epoch: 24 [2800/3696 (76%)]\tLoss: 0.124508\n",
      "Train Epoch: 24 [3200/3696 (87%)]\tLoss: 0.127101\n",
      "Train Epoch: 24 [3600/3696 (97%)]\tLoss: 0.144897\n",
      "Validation:\n",
      "[Epoch: 24, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 45.425\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 288.18s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 25 [0/3696 (0%)]\tLoss: 0.131520\n",
      "Train Epoch: 25 [400/3696 (11%)]\tLoss: 0.136473\n",
      "Train Epoch: 25 [800/3696 (22%)]\tLoss: 0.133885\n",
      "Train Epoch: 25 [1200/3696 (32%)]\tLoss: 0.109012\n",
      "Train Epoch: 25 [1600/3696 (43%)]\tLoss: 0.102910\n",
      "Train Epoch: 25 [2000/3696 (54%)]\tLoss: 0.117917\n",
      "Train Epoch: 25 [2400/3696 (65%)]\tLoss: 0.116642\n",
      "Train Epoch: 25 [2800/3696 (76%)]\tLoss: 0.100671\n",
      "Train Epoch: 25 [3200/3696 (87%)]\tLoss: 0.099144\n",
      "Train Epoch: 25 [3600/3696 (97%)]\tLoss: 0.125011\n",
      "Validation:\n",
      "[Epoch: 25, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 42.795\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 281.78s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 26 [0/3696 (0%)]\tLoss: 0.099042\n",
      "Train Epoch: 26 [400/3696 (11%)]\tLoss: 0.108454\n",
      "Train Epoch: 26 [800/3696 (22%)]\tLoss: 0.116754\n",
      "Train Epoch: 26 [1200/3696 (32%)]\tLoss: 0.096833\n",
      "Train Epoch: 26 [1600/3696 (43%)]\tLoss: 0.098024\n",
      "Train Epoch: 26 [2000/3696 (54%)]\tLoss: 0.113449\n",
      "Train Epoch: 26 [2400/3696 (65%)]\tLoss: 0.096068\n",
      "Train Epoch: 26 [2800/3696 (76%)]\tLoss: 0.096625\n",
      "Train Epoch: 26 [3200/3696 (87%)]\tLoss: 0.114703\n",
      "Train Epoch: 26 [3600/3696 (97%)]\tLoss: 0.094894\n",
      "Validation:\n",
      "[Epoch: 26, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 41.150\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 288.26s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 27 [0/3696 (0%)]\tLoss: 0.118134\n",
      "Train Epoch: 27 [400/3696 (11%)]\tLoss: 0.114524\n",
      "Train Epoch: 27 [800/3696 (22%)]\tLoss: 0.119055\n",
      "Train Epoch: 27 [1200/3696 (32%)]\tLoss: 0.111841\n",
      "Train Epoch: 27 [1600/3696 (43%)]\tLoss: 0.121878\n",
      "Train Epoch: 27 [2000/3696 (54%)]\tLoss: 0.100262\n",
      "Train Epoch: 27 [2400/3696 (65%)]\tLoss: 0.113368\n",
      "Train Epoch: 27 [2800/3696 (76%)]\tLoss: 0.090816\n",
      "Train Epoch: 27 [3200/3696 (87%)]\tLoss: 0.095542\n",
      "Train Epoch: 27 [3600/3696 (97%)]\tLoss: 0.103828\n",
      "Validation:\n",
      "[Epoch: 27, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 39.830\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 281.94s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 28 [0/3696 (0%)]\tLoss: 0.117206\n",
      "Train Epoch: 28 [400/3696 (11%)]\tLoss: 0.100059\n",
      "Train Epoch: 28 [800/3696 (22%)]\tLoss: 0.087977\n",
      "Train Epoch: 28 [1200/3696 (32%)]\tLoss: 0.098873\n",
      "Train Epoch: 28 [1600/3696 (43%)]\tLoss: 0.087399\n",
      "Train Epoch: 28 [2000/3696 (54%)]\tLoss: 0.098774\n",
      "Train Epoch: 28 [2400/3696 (65%)]\tLoss: 0.088126\n",
      "Train Epoch: 28 [2800/3696 (76%)]\tLoss: 0.116627\n",
      "Train Epoch: 28 [3200/3696 (87%)]\tLoss: 0.099471\n",
      "Train Epoch: 28 [3600/3696 (97%)]\tLoss: 0.106696\n",
      "Validation:\n",
      "[Epoch: 28, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 39.075\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 288.27s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 29 [0/3696 (0%)]\tLoss: 0.110564\n",
      "Train Epoch: 29 [400/3696 (11%)]\tLoss: 0.106339\n",
      "Train Epoch: 29 [800/3696 (22%)]\tLoss: 0.106442\n",
      "Train Epoch: 29 [1200/3696 (32%)]\tLoss: 0.111627\n",
      "Train Epoch: 29 [1600/3696 (43%)]\tLoss: 0.119532\n",
      "Train Epoch: 29 [2000/3696 (54%)]\tLoss: 0.082107\n",
      "Train Epoch: 29 [2400/3696 (65%)]\tLoss: 0.083154\n",
      "Train Epoch: 29 [2800/3696 (76%)]\tLoss: 0.088632\n",
      "Train Epoch: 29 [3200/3696 (87%)]\tLoss: 0.095846\n",
      "Train Epoch: 29 [3600/3696 (97%)]\tLoss: 0.082941\n",
      "Validation:\n",
      "[Epoch: 29, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 37.615\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 281.76s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 30 [0/3696 (0%)]\tLoss: 0.082516\n",
      "Train Epoch: 30 [400/3696 (11%)]\tLoss: 0.108280\n",
      "Train Epoch: 30 [800/3696 (22%)]\tLoss: 0.091862\n",
      "Train Epoch: 30 [1200/3696 (32%)]\tLoss: 0.079200\n",
      "Train Epoch: 30 [1600/3696 (43%)]\tLoss: 0.105817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [2000/3696 (54%)]\tLoss: 0.095110\n",
      "Train Epoch: 30 [2400/3696 (65%)]\tLoss: 0.094764\n",
      "Train Epoch: 30 [2800/3696 (76%)]\tLoss: 0.097335\n",
      "Train Epoch: 30 [3200/3696 (87%)]\tLoss: 0.095962\n",
      "Train Epoch: 30 [3600/3696 (97%)]\tLoss: 0.077044\n",
      "Validation:\n",
      "[Epoch: 30, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 37.197\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 288.31s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 31 [0/3696 (0%)]\tLoss: 0.087937\n",
      "Train Epoch: 31 [400/3696 (11%)]\tLoss: 0.090727\n",
      "Train Epoch: 31 [800/3696 (22%)]\tLoss: 0.093825\n",
      "Train Epoch: 31 [1200/3696 (32%)]\tLoss: 0.087951\n",
      "Train Epoch: 31 [1600/3696 (43%)]\tLoss: 0.075064\n",
      "Train Epoch: 31 [2000/3696 (54%)]\tLoss: 0.090388\n",
      "Train Epoch: 31 [2400/3696 (65%)]\tLoss: 0.094324\n",
      "Train Epoch: 31 [2800/3696 (76%)]\tLoss: 0.100838\n",
      "Train Epoch: 31 [3200/3696 (87%)]\tLoss: 0.087702\n",
      "Train Epoch: 31 [3600/3696 (97%)]\tLoss: 0.100132\n",
      "Validation:\n",
      "[Epoch: 31, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 35.413\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 282.01s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 32 [0/3696 (0%)]\tLoss: 0.096307\n",
      "Train Epoch: 32 [400/3696 (11%)]\tLoss: 0.072419\n",
      "Train Epoch: 32 [800/3696 (22%)]\tLoss: 0.097593\n",
      "Train Epoch: 32 [1200/3696 (32%)]\tLoss: 0.103024\n",
      "Train Epoch: 32 [1600/3696 (43%)]\tLoss: 0.078522\n",
      "Train Epoch: 32 [2000/3696 (54%)]\tLoss: 0.070820\n",
      "Train Epoch: 32 [2400/3696 (65%)]\tLoss: 0.074681\n",
      "Train Epoch: 32 [2800/3696 (76%)]\tLoss: 0.099960\n",
      "Train Epoch: 32 [3200/3696 (87%)]\tLoss: 0.090625\n",
      "Train Epoch: 32 [3600/3696 (97%)]\tLoss: 0.070516\n",
      "Validation:\n",
      "[Epoch: 32, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 34.420\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 288.39s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 33 [0/3696 (0%)]\tLoss: 0.070117\n",
      "Train Epoch: 33 [400/3696 (11%)]\tLoss: 0.072609\n",
      "Train Epoch: 33 [800/3696 (22%)]\tLoss: 0.094654\n",
      "Train Epoch: 33 [1200/3696 (32%)]\tLoss: 0.068082\n",
      "Train Epoch: 33 [1600/3696 (43%)]\tLoss: 0.098444\n",
      "Train Epoch: 33 [2000/3696 (54%)]\tLoss: 0.109016\n",
      "Train Epoch: 33 [2400/3696 (65%)]\tLoss: 0.082908\n",
      "Train Epoch: 33 [2800/3696 (76%)]\tLoss: 0.078466\n",
      "Train Epoch: 33 [3200/3696 (87%)]\tLoss: 0.067856\n",
      "Train Epoch: 33 [3600/3696 (97%)]\tLoss: 0.100590\n",
      "Validation:\n",
      "[Epoch: 33, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 33.730\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 281.89s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 34 [0/3696 (0%)]\tLoss: 0.069756\n",
      "Train Epoch: 34 [400/3696 (11%)]\tLoss: 0.080358\n",
      "Train Epoch: 34 [800/3696 (22%)]\tLoss: 0.078724\n",
      "Train Epoch: 34 [1200/3696 (32%)]\tLoss: 0.083342\n",
      "Train Epoch: 34 [1600/3696 (43%)]\tLoss: 0.095091\n",
      "Train Epoch: 34 [2000/3696 (54%)]\tLoss: 0.083736\n",
      "Train Epoch: 34 [2400/3696 (65%)]\tLoss: 0.066279\n",
      "Train Epoch: 34 [2800/3696 (76%)]\tLoss: 0.067592\n",
      "Train Epoch: 34 [3200/3696 (87%)]\tLoss: 0.115993\n",
      "Train Epoch: 34 [3600/3696 (97%)]\tLoss: 0.085669\n",
      "Validation:\n",
      "[Epoch: 34, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 32.976\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 288.21s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 35 [0/3696 (0%)]\tLoss: 0.064480\n",
      "Train Epoch: 35 [400/3696 (11%)]\tLoss: 0.063507\n",
      "Train Epoch: 35 [800/3696 (22%)]\tLoss: 0.089916\n",
      "Train Epoch: 35 [1200/3696 (32%)]\tLoss: 0.091133\n",
      "Train Epoch: 35 [1600/3696 (43%)]\tLoss: 0.088852\n",
      "Train Epoch: 35 [2000/3696 (54%)]\tLoss: 0.081269\n",
      "Train Epoch: 35 [2400/3696 (65%)]\tLoss: 0.062968\n",
      "Train Epoch: 35 [2800/3696 (76%)]\tLoss: 0.066426\n",
      "Train Epoch: 35 [3200/3696 (87%)]\tLoss: 0.061680\n",
      "Train Epoch: 35 [3600/3696 (97%)]\tLoss: 0.065616\n",
      "Validation:\n",
      "[Epoch: 35, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 31.183\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 281.95s \n",
      "-----------------------------------------------------------------------------------------\n",
      "Train Epoch: 36 [0/3696 (0%)]\tLoss: 0.077000\n"
     ]
    }
   ],
   "source": [
    "epoch =15\n",
    "best_loss = None\n",
    "#if load_model:\n",
    "#    best_loss = test(0)\n",
    "try:\n",
    "    for epoch in range(1, epoch + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train(epoch)\n",
    "        test_loss = test(epoch)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s '.format(\n",
    "            epoch, time.time() - epoch_start_time))\n",
    "        print('-' * 89)\n",
    "\n",
    "        if best_loss is None or test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            with open(\"model2.pt\", 'wb') as fp:\n",
    "                state = model.state_dict()\n",
    "                torch.save(state, fp)\n",
    "        else:\n",
    "            adjust_learning_rate(optimizer, 0.5, epoch)\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "[Epoch: 1, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 2.024\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 32.78s \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Load model \n",
    "with open(\"model2.pt\", 'rb') as fp:\n",
    "    state = torch.load(fp)\n",
    "    model.load_state_dict(state)\n",
    "    load_model = True\n",
    "    \n",
    "    \n",
    "#Test\n",
    "epoch_start_time = time.time()\n",
    "test_loss = test(1)\n",
    "print('-' * 89)\n",
    "print('| end of epoch {:3d} | time: {:5.2f}s '.format(\n",
    "    1, time.time() - epoch_start_time))\n",
    "print('-' * 89)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 144)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=np.empty([128,144])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:\n",
      "[Epoch: 1, numImages:   924]\n",
      "Acc:0.9948884891511844, Acc_class:0.5, mIoU:0.4974442445755922, fwIoU: 0.9898031058455264\n",
      "Loss: 2.028\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 16.64s \n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "demo = True\n",
    "out=np.empty([128,144])\n",
    "label=np.empty([128,144])\n",
    "#Test\n",
    "epoch_start_time = time.time()\n",
    "test_loss = test(1)\n",
    "print('-' * 89)\n",
    "print('| end of epoch {:3d} | time: {:5.2f}s '.format(\n",
    "    1, time.time() - epoch_start_time))\n",
    "print('-' * 89)\n",
    "\n",
    "demo=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f406aaba438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(out)\n",
    "plt.subplot(122)\n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model \n",
    "with open(\"model.pt\", 'rb') as fp:\n",
    "    state = torch.load(fp)\n",
    "    model.load_state_dict(state)\n",
    "    load_model = True\n",
    "    \n",
    "    \n",
    "#Test\n",
    "epoch_start_time = time.time()\n",
    "test_loss = test(1)\n",
    "print('-' * 89)\n",
    "print('| end of epoch {:3d} | time: {:5.2f}s '.format(\n",
    "    1, time.time() - epoch_start_time))\n",
    "print('-' * 89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WMSegmentation(Dataset):\n",
    "    def __init__(self,filenames,masknames,transform=None):\n",
    "        \n",
    "        self.image_names = filenames\n",
    "        self.mask_names = masknames\n",
    "        self.transform= transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.image_names) == len(self.mask_names)\n",
    "        \n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_names[idx]\n",
    "        mask = self.mask_names[idx]\n",
    "        \n",
    "        image = Image.open(image)\n",
    "        mask= Image.open(mask)\n",
    "        \n",
    "        # Add transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image); #image = torch.cat((image,image,image),0)\n",
    "            mask = self.transform(mask)[0,:,:];# mask = torch.cat((mask,mask,mask),0)\n",
    "        \n",
    "        sample = {\"image\": image, \"mask\":mask }\n",
    "        \n",
    "        \n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(WMSegmentation(\n",
    "    Xtrain,ytrain,transform = transforms.ToTensor()),\n",
    "                              batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 144])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(ytrain[2])\n",
    "transform = transforms.ToTensor()\n",
    "im = transform(image)\n",
    "\n",
    "print(im.shape)\n",
    "im2 = torch.cat((im,im,im),0)\n",
    "im2.shape\n",
    "\n",
    "np.unique(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DeepLabv3 Model download and change the head for your prediction\"\"\"\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def createDeepLabv3(outputchannels=2):\n",
    "    \"\"\"DeepLabv3 class with custom head\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 1.\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n",
    "                                                    progress=True)\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fjmoya/.cache/torch/hub/milesial_Pytorch-UNet_master\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load('milesial/Pytorch-UNet', 'unet_carvana')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-eaa50058331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1824\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1827\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0;31m# dim == 3 or dim > 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "my_cnn = createDeepLabv3()\n",
    "my_cnn.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_cnn.parameters(), lr=0.001, momentum=0.9)\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, masks = data['image'].to(device), data['mask'].to(device)\n",
    "        #inputs, labels = data['image'], data['label']\n",
    "       \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = my_cnn(inputs)[\"out\"]\n",
    "        \n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2 == 1.99:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"The execution time is: {end_time-start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, dataloaders, optimizer, metrics, bpath,\n",
    "                num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    # Use gpu if available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # Initialize the log file for training and testing loss and metrics\n",
    "    fieldnames = ['epoch', 'Train_loss', 'Test_loss'] + \\\n",
    "        [f'Train_{m}' for m in metrics.keys()] + \\\n",
    "        [f'Test_{m}' for m in metrics.keys()]\n",
    "    with open(os.path.join(bpath, 'log.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        # Initialize batch summary\n",
    "        batchsummary = {a: [0] for a in fieldnames}\n",
    "\n",
    "        for phase in ['Train', 'Test']:\n",
    "            if phase == 'Train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in tqdm(iter(dataloaders[phase])):\n",
    "                inputs = sample['image'].to(device)\n",
    "                masks = sample['mask'].to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'Train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs['out'], masks)\n",
    "                    y_pred = outputs['out'].data.cpu().numpy().ravel()\n",
    "                    y_true = masks.data.cpu().numpy().ravel()\n",
    "                    for name, metric in metrics.items():\n",
    "                        if name == 'f1_score':\n",
    "                            # Use a classification threshold of 0.1\n",
    "                            batchsummary[f'{phase}_{name}'].append(\n",
    "                                metric(y_true > 0, y_pred > 0.1))\n",
    "                        else:\n",
    "                            batchsummary[f'{phase}_{name}'].append(\n",
    "                                metric(y_true.astype('uint8'), y_pred))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            batchsummary['epoch'] = epoch\n",
    "            epoch_loss = loss\n",
    "            batchsummary[f'{phase}_loss'] = epoch_loss.item()\n",
    "            print('{} Loss: {:.4f}'.format(phase, loss))\n",
    "        for field in fieldnames[3:]:\n",
    "            batchsummary[field] = np.mean(batchsummary[field])\n",
    "        print(batchsummary)\n",
    "        with open(os.path.join(bpath, 'log.csv'), 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(batchsummary)\n",
    "            # deep copy the model\n",
    "            if phase == 'Test' and loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Lowest Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
